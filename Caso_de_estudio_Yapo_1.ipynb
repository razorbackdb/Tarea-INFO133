{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook está vinculado al caso de estudio \"Yapo\" (ver el [documento](https://docs.google.com/document/d/1SwhwMOyG7-cmzasDeisQZ_NzX5v2VoZ7--lI4UhJz_U/edit#heading=h.5qaqs0frqkx4) de presentación). Se busca construir una base de datos de anuncios en Los Rios recopilando algunos anuncios de Yapo.cl.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Construcción de la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector \n",
    "\n",
    "db_connection = mysql.connector.connect(user=\"root\",host=\"localhost\",password=\"root\")\n",
    "cursor = db_connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"DROP DATABASE Yapo2;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"CREATE DATABASE Yapo2;\")\n",
    "cursor.execute(\"USE Yapo2\")\n",
    "\n",
    "#tabla vendedor\n",
    "cursor.execute(\"CREATE TABLE vendedor (\"+\n",
    "               \"id_vendedor VARCHAR(130) PRIMARY KEY, nombre VARCHAR(100), ciudad VARCHAR(30), codigo_region VARCHAR(7), \"+\n",
    "               \"nombre_region VARCHAR(30), \"+\n",
    "               \"fecha_inscripcion DATE)\")\n",
    "\n",
    "#tabla anuncio\n",
    "cursor.execute(\"CREATE TABLE anuncio (url VARCHAR(300) PRIMARY KEY, \"+\n",
    "               \"titulo VARCHAR(200), descripcion MEDIUMTEXT, precio INT, moneda VARCHAR(2), fecha_publicacion DATE, categoria VARCHAR(50), \"\n",
    "               +\"id_vendedor VARCHAR(130), FOREIGN KEY (id_vendedor) REFERENCES vendedor(id_vendedor))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Scrapping de datos para llenar nuestra base de datos Yapo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen as uReq\n",
    "import urllib.request\n",
    "\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la librería Selenium, abriremos un navegador Chrome, en la página de los anuncios de Yapo en la región de Los Rios... __(UPDATE: todo chile)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Firefox()\n",
    "\n",
    "myUrl = 'https://www.yapo.cl/chile/todos_los_avisos?ca=12_s&l=0'\n",
    "#myUrl = 'https://www.yapo.cl/los_rios/todos_los_avisos?ca=11_s&l=0&w=1&cmn=243'\n",
    "browser.get(myUrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la librería BeautifulSoup, realizamos un scrapping del código HTML para recuperar el enlace de la \"última página\"..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageSoup = soup(browser.page_source, 'html.parser')\n",
    "\n",
    "pages = pageSoup.find('span',  {'class', 'nohistory FloatRight'}).a['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El parametro 'o' de la URL corresponde al número de la pagina en la lista de anuncios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pages.rfind('=')\n",
    "print(index)\n",
    "lastPage = int(pages[index+1:])\n",
    "print(lastPage)\n",
    "root_pages = pages[:index+1]\n",
    "print(root_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- la variable \"index\" permite identificar el indice del último caracter '='.\n",
    "\n",
    "- la variable \"lastPage\" permite identificar el numero de la última página en la URL.\n",
    "\n",
    "- la variable \"root_pages\" permite aislar la cadena de caracteres que corresponde a la raiz de la URL (sin el numero de página).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezaremos la iteración sobre cada página que escrapear..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def convert_date(yapo_date):\n",
    "    month=yapo_date.split(\" \")[0]\n",
    "    year=yapo_date.split(\" \")[1]\n",
    "    \n",
    "    convert = {'Enero' : 1,\n",
    "            'Febrero' : 2,\n",
    "            'Marzo' : 3,\n",
    "            'Abril' : 4,\n",
    "            'Mayo' : 5,\n",
    "            'Junio' : 6,\n",
    "            'Julio' : 7,\n",
    "            'Agosto' : 8,\n",
    "            'Septiembre' : 9, \n",
    "            'Octubre' : 10,\n",
    "            'Noviembre' : 11,\n",
    "            'Diciembre' : 12\n",
    "           }\n",
    "    \n",
    "    \n",
    "    new_date=datetime.date(int(year), convert[month], 1) \n",
    "\n",
    "    return new_date\n",
    "\n",
    "print(convert_date(\"Febrero 2020\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(lastPage):\n",
    "    \n",
    "    #recuperarmos la URL de la pagina corriente\n",
    "    url = root_pages + str(i+1)\n",
    "    \n",
    "    #con Selenium, vamos en navegar en esta página\n",
    "    browser.get(url)\n",
    "    \n",
    "    #empezamos el scrapping de la pagina corriente\n",
    "    pageSoup = soup(browser.page_source, 'html.parser')\n",
    "    \n",
    "    #recuperamos todos los tags HTML que corresponden a la lista de anuncios en esta pagina\n",
    "    links = pageSoup.findAll('td', {'class' : 'thumbs_subject'})\n",
    "    \n",
    "    #empezamos a iterar sobre cada anuncio\n",
    "    for link in links:\n",
    "        \n",
    "        #todos los datos que necesitamos encontrar\n",
    "        url, titulo, descripcion, precio, fecha_publicacion, categoria=\"\",\"\",\"\",None,\"\", \"\"\n",
    "        nombre, ciudad, codigo_region, nombre_region, fecha_inscripcion=\"\",\"\",\"\",\"\",\"\"\n",
    "        \n",
    "        #Navegamos hacia la pagina del anuncio\n",
    "        url=link.find('a',{'class':'title'})['href']\n",
    "        print(url)\n",
    "        browser.get(link.find('a',{'class':'title'})['href'])\n",
    "\n",
    "        #RECUPERAMOS LA FECHA DE PUBLICACION DEL ANUNCIO          \n",
    "        pageSoup = soup(browser.page_source, 'html.parser')\n",
    "        if(pageSoup.find('time')):\n",
    "            datetime_raw = pageSoup.find('time').attrs['datetime']\n",
    "            date_publication_raw=datetime_raw.split(\"T\")[0]\n",
    "            date_publication_raw=  date_publication_raw.split(\"-\")\n",
    "            \n",
    "            date_publication=datetime.date(int(date_publication_raw[0]), int(date_publication_raw[1]),\n",
    "                                           int(date_publication_raw[2]))\n",
    "            print(\"datetime:\")\n",
    "            print(date_publication)\n",
    "        \n",
    "        #RECUPERAMOS EL TITULO DEL ANUNCIO           \n",
    "        pageSoup = soup(browser.page_source, 'html.parser')\n",
    "        if(pageSoup.find('h1', {\"id\" : \"da_subject\"})):\n",
    "            titulo = pageSoup.find('h1', {\"id\" : \"da_subject\"}).text.strip()\n",
    "            print(titulo)\n",
    "            \n",
    "        #RECUPERAMOS LA DESCRIPCION DEL ANUNCIO\n",
    "        if(pageSoup.find('div', {\"class\" : \"description\"})):\n",
    "            try:\n",
    "                descripcion = pageSoup.find('div', {\"class\" : \"description\"}).text.split(' ', 1)[1].strip().replace(u'\\n', u' ')\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        #RECUPERAMOS EL PRECIO DEL ANUNCIO\n",
    "        if(pageSoup.find('div', {\"class\" : \"price text-right\"})):\n",
    "            precio_raw = pageSoup.find('div', {\"class\" : \"price text-right\"}).text.strip().replace(u'\\n', u' ').replace(u'\\t', u'')\n",
    "            precio_raw = precio_raw.split(\" \")\n",
    "            moneda = precio_raw[0]\n",
    "            precio = precio_raw[1].split(\",\")[0].replace(u'.', u'')\n",
    "            print(\"precio:\"+precio)\n",
    "            \n",
    "        #RECUPERAMOS LA CATEGORIA DEL ANUNCIO\n",
    "        if(pageSoup.find('div', {\"class\" : \"breadcrumbs\"})):\n",
    "            categoria = pageSoup.find('div', {\"class\" : \"breadcrumbs\"}).find('a', {\"id\" : \"breadcrumb_category\"}).find('strong').text.strip().replace(u'\\n', u' ')\n",
    "            print(categoria)\n",
    "            \n",
    "        \n",
    "        #RECUPERAMOS EL NOMBRE DEL VENDEDOR, SU FECHA DE INSCRIPCION Y SU LOCALIDAD\n",
    "        if(pageSoup.find('aside', {\"class\" : \"sidebar-right\"})):\n",
    "            aside = pageSoup.find('aside', {\"class\" : \"sidebar-right\"})\n",
    "    \n",
    "            #print(aside.find('seller-info'))\n",
    "            \n",
    "            #NOMBRE\n",
    "            if(aside.find('seller-info')!=None):\n",
    "                nombre=aside.find('seller-info').attrs['username']\n",
    "            \n",
    "                #FECHA DE INSCRIPCION\n",
    "                fecha_inscripcion_raw=aside.find('seller-info').attrs['seniority']\n",
    "                try:\n",
    "                    fecha_inscripcion_raw=fecha_inscripcion_raw[len(\"En Yapo desde \"):]\n",
    "                    fecha_inscripcion=convert_date(fecha_inscripcion_raw)\n",
    "                    print(fecha_inscripcion)\n",
    "                except:\n",
    "                    fecha_inscripcion=None\n",
    "                    continue\n",
    "                \n",
    "                #LOCALIDAD\n",
    "                localidad_raw=aside.find('seller-info').attrs['region']\n",
    "            \n",
    "                #print(localidad_raw)\n",
    "            \n",
    "                region_raw=localidad_raw.split(\",\")[0]\n",
    "                ciudad_raw=localidad_raw.split(\",\")[1]\n",
    "            \n",
    "                codigo_region=region_raw.split(\" \")[0]\n",
    "                nombre_region=region_raw[len(codigo_region)+1:]\n",
    "                ciudad=ciudad_raw[1:]\n",
    "                \n",
    "        # LLENAMOS LA BASE DE DATOS: TABLA VENDEDOR\n",
    "        \n",
    "        try:\n",
    "            sql = \"INSERT INTO vendedor (id_vendedor,nombre, ciudad, codigo_region, nombre_region, fecha_inscripcion) VALUES (%s,%s, %s, %s,%s,%s)\"\n",
    "            val = (nombre+\"_\"+codigo_region+\"_\"+ciudad,nombre, ciudad, codigo_region, nombre_region, fecha_inscripcion)\n",
    "            cursor.execute(sql, val)\n",
    "        except Exception as e1:\n",
    "            print(e1)\n",
    "            #continue\n",
    "        \n",
    "        # LLENAMOS LA BASE DE DATOS: TABLA ANUNCIO\n",
    "        try:\n",
    "            sql = \"INSERT INTO anuncio (url, titulo, descripcion, precio, moneda, fecha_publicacion, categoria, id_vendedor) VALUES (%s, %s, %s,%s, %s, %s, %s, %s)\"\n",
    "            val = (url, titulo, descripcion, int(precio), moneda, date_publication, categoria, nombre+\"_\"+codigo_region+\"_\"+ciudad)\n",
    "            cursor.execute(sql, val)\n",
    "        except Exception as e2:\n",
    "            print(e2)\n",
    "            #continue\n",
    "        \n",
    "        cursor.execute(\"COMMIT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
